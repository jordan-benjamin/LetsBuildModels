{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GRU.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "esH5jZeZ4aWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsGWwht41mCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GRUCell(nn.Module):\n",
        "  def __init__(self, input_depth, hidden_depth):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.input_depth = input_depth\n",
        "    self.hidden_depth = hidden_depth\n",
        "    \n",
        "    concat_depth = input_depth + hidden_depth\n",
        "\n",
        "    self.forget = nn.Sequential(nn.Linear(concat_depth, hidden_depth), nn.Sigmoid())\n",
        "    self.update = nn.Sequential(nn.Linear(concat_depth, hidden_depth), nn.Sigmoid())\n",
        "\n",
        "    self.output = nn.Sequential(nn.Linear(concat_depth, hidden_depth), nn.Tanh())\n",
        "\n",
        "    self.hidden = None\n",
        "  \n",
        "  def reset(self):\n",
        "    self.hidden = None\n",
        "  \n",
        "  def forward(self, token):\n",
        "    if self.hidden is None:\n",
        "      self.hidden = torch.zeros(token.shape[0], self.hidden_depth)\n",
        "\n",
        "    concat = torch.cat([token, self.hidden], dim=1)\n",
        "\n",
        "    forget = self.forget(concat)\n",
        "    update = self.update(concat)\n",
        "\n",
        "    forget_concat = torch.cat([token, self.hidden * forget], dim=1)\n",
        "\n",
        "    output = self.output(forget_concat)\n",
        "\n",
        "    self.hidden = update * self.hidden + (1 - update) * output \n",
        "\n",
        "    return self.hidden\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZCS7HSY6AfC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GRU(nn.Module):\n",
        "  def __init__(self, input_depth, hidden_depth, num_layers): \n",
        "    super().__init__()\n",
        "\n",
        "    self.input_depth = input_depth\n",
        "    self.hidden_depth = hidden_depth\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.layers = [GRUCell(input_depth, hidden_depth) for _ in range(num_layers)]\n",
        "\n",
        "  def reset(self):\n",
        "    for l in self.layers: l.reset()\n",
        "\n",
        "  # Inp takes shape (sequence_length, batch_size, input_depth)\n",
        "  def forward(self, inp):\n",
        "    \n",
        "    self.reset()\n",
        "\n",
        "    hiddens = []\n",
        "\n",
        "\n",
        "    for token in inp:\n",
        "      carry = token\n",
        "      for l in self.layers:\n",
        "        hidden = l(carry)\n",
        "        carry = hidden\n",
        "      \n",
        "      hiddens.append(carry)\n",
        "\n",
        "    return hiddens\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo-v1ZRHB5ql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = GRU(10, 10, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1LK-cs0CDZr",
        "colab_type": "code",
        "outputId": "66461a36-2670-4a0b-a60f-18cf879bc3ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "l(torch.randn(3, 2, 10))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[-0.0041, -0.1195,  0.0676,  0.0983, -0.0706,  0.0321, -0.0816, -0.1101,\n",
              "          -0.0573,  0.0662],\n",
              "         [-0.0228, -0.0271,  0.0494,  0.1206, -0.0278,  0.0045, -0.0383, -0.0724,\n",
              "          -0.0694,  0.1469]], grad_fn=<AddBackward0>),\n",
              " tensor([[ 0.0485, -0.1375,  0.0805,  0.1373, -0.0485,  0.0473, -0.1241, -0.1486,\n",
              "          -0.0717,  0.1793],\n",
              "         [-0.0096, -0.1022,  0.0942,  0.1735, -0.0580,  0.0479, -0.1317, -0.1305,\n",
              "          -0.0725,  0.1653]], grad_fn=<AddBackward0>),\n",
              " tensor([[ 0.0271, -0.1816,  0.0940,  0.1594, -0.0741,  0.0546, -0.1443, -0.1748,\n",
              "          -0.1018,  0.2152],\n",
              "         [-0.0541, -0.0950,  0.1355,  0.1998, -0.0739,  0.0271, -0.1742, -0.1629,\n",
              "          -0.1016,  0.1918]], grad_fn=<AddBackward0>)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qmn5FX5i1slp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}