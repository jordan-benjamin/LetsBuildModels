{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "esH5jZeZ4aWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsGWwht41mCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMCell(nn.Module):\n",
        "  def __init__(self, input_depth, hidden_depth):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.input_depth = input_depth\n",
        "    self.hidden_depth = hidden_depth\n",
        "    \n",
        "    concat_depth = input_depth + hidden_depth\n",
        "\n",
        "    self.forget = nn.Sequential(nn.Linear(concat_depth, hidden_depth), nn.Sigmoid())\n",
        "    self.input = nn.Sequential(nn.Linear(concat_depth, hidden_depth), nn.Sigmoid())\n",
        "\n",
        "    self.new_cell = nn.Sequential(nn.Linear(concat_depth, hidden_depth), nn.Tanh())\n",
        "    self.output = nn.Sequential(nn.Linear(concat_depth, hidden_depth), nn.Sigmoid())\n",
        "\n",
        "    self.cell = None\n",
        "    self.hidden = None\n",
        "  \n",
        "  def reset(self):\n",
        "    self.cell = None\n",
        "    self.hidden = None\n",
        "  \n",
        "  def forward(self, token):\n",
        "    if self.hidden is None:\n",
        "      self.hidden = torch.zeros(token.shape[0], self.hidden_depth)\n",
        "    \n",
        "    if self.cell is None:\n",
        "      self.cell = torch.zeros(token.shape[0], self.hidden_depth)\n",
        "\n",
        "    concat = torch.cat([token, self.hidden], dim=1)\n",
        "\n",
        "    forget = self.forget(concat)\n",
        "    inpt = self.input(concat)\n",
        "    new_cell = self.new_cell(concat)\n",
        "\n",
        "    self.cell = self.cell * forget + new_cell * inpt\n",
        "\n",
        "    output = self.output(concat)\n",
        "\n",
        "    self.hidden = torch.tanh(self.cell) * output \n",
        "\n",
        "    return self.hidden, self.cell\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZCS7HSY6AfC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "  def __init__(self, input_depth, hidden_depth, num_layers): \n",
        "    super().__init__()\n",
        "\n",
        "    self.input_depth = input_depth\n",
        "    self.hidden_depth = hidden_depth\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.layers = [LSTMCell(input_depth, hidden_depth) for _ in range(num_layers)]\n",
        "\n",
        "  def reset(self):\n",
        "    for l in self.layers: l.reset()\n",
        "\n",
        "  # Inp takes shape (sequence_length, batch_size, input_depth)\n",
        "  def forward(self, inp):\n",
        "    \n",
        "    self.reset()\n",
        "\n",
        "    hiddens = []\n",
        "\n",
        "\n",
        "    for token in inp:\n",
        "      carry = token\n",
        "      for l in self.layers:\n",
        "        hidden, cell = l(carry)\n",
        "        carry = hidden\n",
        "      \n",
        "      hiddens.append(carry)\n",
        "\n",
        "    return hiddens\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo-v1ZRHB5ql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = LSTM(10, 10, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1LK-cs0CDZr",
        "colab_type": "code",
        "outputId": "0a883c3f-46c5-4c9d-a16e-cd629c844434",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "l(torch.randn(3, 2, 10))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[-0.0193, -0.0183, -0.0331, -0.0252,  0.0037,  0.0604,  0.0005,  0.0384,\n",
              "           0.0047,  0.0080],\n",
              "         [-0.0284, -0.0091, -0.0374, -0.0258,  0.0147,  0.0492, -0.0038,  0.0198,\n",
              "           0.0003,  0.0077]], grad_fn=<MulBackward0>),\n",
              " tensor([[-5.0068e-02, -4.2120e-02, -3.7415e-02, -2.2011e-02,  3.0578e-02,\n",
              "           6.6465e-02, -3.6155e-03,  3.3229e-02,  9.7587e-03, -6.9730e-05],\n",
              "         [-3.8661e-02, -1.3510e-02, -2.3087e-02, -2.8316e-02,  1.8454e-02,\n",
              "           4.9066e-02,  8.1171e-03,  2.3087e-02, -1.3406e-03,  2.1450e-02]],\n",
              "        grad_fn=<MulBackward0>),\n",
              " tensor([[-0.0304, -0.0007, -0.0285, -0.0291, -0.0003,  0.0617, -0.0069,  0.0173,\n",
              "          -0.0024, -0.0054],\n",
              "         [-0.0303, -0.0411, -0.0392, -0.0303,  0.0118,  0.0637,  0.0016,  0.0330,\n",
              "           0.0088,  0.0100]], grad_fn=<MulBackward0>)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    }
  ]
}